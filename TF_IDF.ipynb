{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv9H4D6ccjt0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEJJFdDhcmVc",
        "outputId": "04e03f69-1a59-4a4c-aa46-f0da73a2edda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = pd.read_csv(\"amazon_reviews.txt\", delimiter= '\\t', header= None)\n",
        "df.columns=[\"reviews\",\"class\"]\n",
        "df.head()\n",
        "df[\"class\"].shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccFhtjp3cuDk",
        "outputId": "96d516b7-7e5d-4936-a46f-f3ac36c76098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Xel-_KczlW",
        "outputId": "dae492eb-53d5-4b61-98b7-49ce87fe6aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "def prepocessed(dataframe):\n",
        "    all_reviews = list()\n",
        "    line = df[\"reviews\"].values.tolist()\n",
        "    for text in line:\n",
        "        text = text.lower()\n",
        "        pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "        text = pattern.sub('', text)\n",
        "        text = re.sub(r\"[,.\\\"!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\n",
        "        tokens = word_tokenize(text)\n",
        "        table = str.maketrans('', '', string.punctuation)\n",
        "        stripped = [w.translate(table) for w in tokens]\n",
        "        words = [word for word in stripped if word.isalpha()]\n",
        "        stop_words = set(stopwords.words(\"english\"))\n",
        "        stop_words.discard(\"not\")\n",
        "        PS = PorterStemmer()\n",
        "        words = [PS.stem(w) for w in words if not w in stop_words]\n",
        "        words = ' '.join(words)\n",
        "        all_reviews.append(words)\n",
        "    return all_reviews\n",
        "all_reviews = prepocessed(df)\n",
        "all_reviews[0:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['way plug us unless go convert',\n",
              " 'good case excel valu',\n",
              " 'great jawbon',\n",
              " 'tie charger convers last minutesmajor problem',\n",
              " 'mic great',\n",
              " 'jiggl plug get line right get decent volum',\n",
              " 'sever dozen sever hundr contact imagin fun send one one',\n",
              " 'razr ownery must',\n",
              " 'needless say wast money',\n",
              " 'wast money time']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIdQJibic8v3",
        "outputId": "694b65c4-c2c1-4731-fba4-0cd17085523b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "TV = TfidfVectorizer(min_df=3)   \n",
        "X = TV.fit_transform(all_reviews).toarray()\n",
        "y = df[[\"class\"]].to_numpy()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 428)\n",
            "(1000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6gN5tx-dImx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 4)\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nI3BIpSdL_P",
        "outputId": "9dcaec3e-02a4-4400-9e73-9382e101a1aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(criterion=\"entropy\", random_state=41)\n",
        "model.fit(X_train,y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(f1_score(y_test, y_pred))\n",
        "print(precision_score(y_test, y_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.785\n",
            "0.7922705314009661\n",
            "0.82\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}